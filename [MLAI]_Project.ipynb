{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[MLAI] Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ennTzcMfWbr1",
        "colab_type": "text"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfcSocyz7xLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'keras'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jz3SXYtGkSl",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyWOQ7ceGlkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from random import shuffle\n",
        "\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bky2gGCc296",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree('test') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on6-T32ai4Te",
        "colab_type": "text"
      },
      "source": [
        "**Utility Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbXa_Qc5i8lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization(input_shape=(224, 224, 3)))\n",
        "  model.add(Conv2D(filters=16, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=256, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "\n",
        "  model.add(Dense(133, activation='softmax'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def compile_model(model, _opt='adam', _loss='categorical_crossentropy', _metrics=['accuracy']):\n",
        "  model.compile(_opt, _loss, _metrics)\n",
        "  return model\n",
        "\n",
        "def set_checkpointer(_filePath):\n",
        "  checkpointer = ModelCheckpoint(filepath=_filePath, verbose=1, \n",
        "                                 save_best_only=True)\n",
        "  return checkpointer\n",
        "\n",
        "def train(model, num_epochs, batch_size, step_size, train_data, train_target, valid_data, valid_target, checkpointer):\n",
        "  model.fit_generator(datagen.flow(train_data, train_target, batch_size=batch_size),\n",
        "                    validation_data=(valid_data, valid_target), \n",
        "                    steps_per_epoch=train_data.shape[0] // batch_size,\n",
        "                    epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "# def load_best_model(model, _filePath):\n",
        "#   model.load_weights(_filePath)\n",
        "\n",
        "def test(model, test_data, test_target):\n",
        "  dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_data]\n",
        "\n",
        "  test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_target, axis=1))/len(dog_breed_predictions)\n",
        "  print('Test accuracy: %.4f%%' % test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHiId7xUeJpT",
        "colab_type": "text"
      },
      "source": [
        "**Dataset preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmQ5xfseM8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./mlai/Images'):\n",
        "  !git clone https://github.com/jmagdeska/mlai.git\n",
        "\n",
        "DATA_DIR = 'mlai/Images'\n",
        "\n",
        "if not os.path.isdir('train'):\n",
        "  os.mkdir('train')\n",
        "if not os.path.isdir('valid'):\n",
        "  os.mkdir('valid')\n",
        "if not os.path.isdir('test'):\n",
        "  os.mkdir('test')\n",
        "\n",
        "for path, dirs, files in os.walk(DATA_DIR):\n",
        "  dirs.sort(key = lambda x: x.lower())\n",
        "  num_samples = len(files)\n",
        "  i = 0\n",
        "  \n",
        "  l = (int)(0.8*num_samples)\n",
        "  if l != 0:\n",
        "    train_len = int(0.8*l)\n",
        "    valid_len = l - train_len\n",
        "    test_len = num_samples - l\n",
        "    print(train_len, valid_len, test_len)\n",
        "\n",
        "    label = path.split(\"/\")[2]\n",
        "    shuffle(files)\n",
        "\n",
        "    for filename in files: \n",
        "      full_path = os.path.join(path, filename)       \n",
        "      if i < train_len:        \n",
        "        dir_name = os.path.join('train', label)\n",
        "        if not os.path.isdir(dir_name):\n",
        "          os.mkdir(os.path.join(\"train\", label))\n",
        "        shutil.move(full_path, dir_name)\n",
        "      elif i < (train_len + valid_len):\n",
        "        dir_name = os.path.join('valid', label)\n",
        "        if not os.path.isdir(dir_name):\n",
        "          os.mkdir(os.path.join(\"valid\", label))\n",
        "        shutil.move(full_path, dir_name)\n",
        "      else:\n",
        "        dir_name = os.path.join('test', label)\n",
        "        if not os.path.isdir(dir_name):\n",
        "          os.mkdir(os.path.join(\"test\", label))\n",
        "        shutil.move(full_path, dir_name)\n",
        "\n",
        "      i += 1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}