{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of [MLAI] Project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmagdeska/mlai/blob/master/%5BMLAI%5D_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ennTzcMfWbr1",
        "colab_type": "text"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfcSocyz7xLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "0f19c20c-99c4-4885-ccd4-7a820cc6628f"
      },
      "source": [
        "!pip3 install 'keras'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jz3SXYtGkSl",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyWOQ7ceGlkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from random import shuffle\n",
        "\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "from keras.preprocessing import image\n",
        "from keras import applications\n",
        "from keras.models import Sequential\n",
        "import os,sys\n",
        "\n",
        "np.random.seed(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bky2gGCc296",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree('test') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on6-T32ai4Te",
        "colab_type": "text"
      },
      "source": [
        "**Utility Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbXa_Qc5i8lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization(input_shape=(224, 224, 3)))\n",
        "  model.add(Conv2D(filters=16, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=256, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "\n",
        "  model.add(Dense(120, activation='softmax'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def alexnet_model():\n",
        "  #Instantiate an empty model\n",
        "  model = Sequential()\n",
        "\n",
        "  # 1st Convolutional Layer\n",
        "  model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding=’valid’))\n",
        "  model.add(Activation(‘relu’))\n",
        "  # Max Pooling\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=’valid’))\n",
        "\n",
        "  # 2nd Convolutional Layer\n",
        "  model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding=’valid’))\n",
        "  model.add(Activation(‘relu’))\n",
        "  # Max Pooling\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=’valid’))\n",
        "\n",
        "  # 3rd Convolutional Layer\n",
        "  model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding=’valid’))\n",
        "  model.add(Activation(‘relu’))\n",
        "\n",
        "  # 4th Convolutional Layer\n",
        "  model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding=’valid’))\n",
        "  model.add(Activation(‘relu’))\n",
        "\n",
        "  # 5th Convolutional Layer\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=’valid’))\n",
        "  model.add(Activation(‘relu’))\n",
        "  # Max Pooling\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=’valid’))\n",
        "\n",
        "  # Passing it to a Fully Connected layer\n",
        "  model.add(Flatten())\n",
        "  # 1st Fully Connected Layer\n",
        "  model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "  model.add(Activation(‘relu’))\n",
        "  # Add Dropout to prevent overfitting\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  # 2nd Fully Connected Layer\n",
        "  model.add(Dense(4096))\n",
        "  model.add(Activation(‘relu’))\n",
        "  # Add Dropout\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  # 3rd Fully Connected Layer\n",
        "  model.add(Dense(1000))\n",
        "  model.add(Activation(‘relu’))\n",
        "  # Add Dropout\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  # Output Layer\n",
        "  model.add(Dense(17))\n",
        "  model.add(Activation(‘softmax’))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def compile_model(model, _opt='adam', _loss='categorical_crossentropy', _metrics=['accuracy']):\n",
        "  model.compile(_opt, _loss, _metrics)\n",
        "  return model\n",
        "\n",
        "def set_checkpointer(_filePath):\n",
        "  checkpointer = ModelCheckpoint(filepath=_filePath, verbose=1, \n",
        "                                 save_best_only=True)\n",
        "  return checkpointer\n",
        "\n",
        "def train(model, num_epochs, batch_size, step_size, train_data, train_target, valid_data, valid_target, checkpointer):\n",
        "  model.fit_generator(datagen.flow(train_data, train_target, batch_size=batch_size),\n",
        "                    validation_data=(valid_data, valid_target), \n",
        "                    steps_per_epoch=train_data.shape[0] // batch_size,\n",
        "                    epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "def fit_gen(model, _train_set, _steps_per_epoch, _epoch, _valid_set, _valid_steps=800):\n",
        "  model.fit_generator(\n",
        "    _train_set,\n",
        "    steps_per_epoch = _steps_per_epoch,\n",
        "    epochs = _epoch,\n",
        "    validation_data = _valid_set,\n",
        "    validation_steps = _valid_steps)\n",
        "  \n",
        "  return model\n",
        "\n",
        "# def load_best_model(model, _filePath):\n",
        "#   model.load_weights(_filePath)\n",
        "\n",
        "def test(model, test_data, test_target):\n",
        "  dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_data]\n",
        "\n",
        "  test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_target, axis=1))/len(dog_breed_predictions)\n",
        "  print('Test accuracy: %.4f%%' % test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHiId7xUeJpT",
        "colab_type": "text"
      },
      "source": [
        "**Dataset preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmQ5xfseM8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./mlai/Images'):\n",
        "  !git clone https://github.com/jmagdeska/mlai.git\n",
        "\n",
        "DATA_DIR = 'mlai/Images'\n",
        "\n",
        "if not os.path.isdir('train'):\n",
        "  os.mkdir('train')\n",
        "if not os.path.isdir('valid'):\n",
        "  os.mkdir('valid')\n",
        "if not os.path.isdir('test'):\n",
        "  os.mkdir('test')\n",
        "\n",
        "for path, dirs, files in os.walk(DATA_DIR):\n",
        "  dirs.sort(key = lambda x: x.lower())\n",
        "  num_samples = len(files)\n",
        "  i = 0\n",
        "  \n",
        "  l = (int)(0.8*num_samples)\n",
        "  if l != 0:\n",
        "    train_len = int(0.8*l)\n",
        "    valid_len = l - train_len\n",
        "    test_len = num_samples - l\n",
        "    #print(train_len, valid_len, test_len)\n",
        "\n",
        "    label = path.split(\"/\")[2]\n",
        "    shuffle(files)\n",
        "\n",
        "    for filename in files: \n",
        "      full_path = os.path.join(path, filename)       \n",
        "      if i < train_len:        \n",
        "        dir_name = os.path.join('train', label)\n",
        "        if not os.path.isdir(dir_name):\n",
        "          os.mkdir(os.path.join(\"train\", label))\n",
        "        shutil.move(full_path, dir_name)\n",
        "      elif i < (train_len + valid_len):\n",
        "        dir_name = os.path.join('valid', label)\n",
        "        if not os.path.isdir(dir_name):\n",
        "          os.mkdir(os.path.join(\"valid\", label))\n",
        "        shutil.move(full_path, dir_name)\n",
        "      else:\n",
        "        dir_name = os.path.join('test', label)\n",
        "        if not os.path.isdir(dir_name):\n",
        "          os.mkdir(os.path.join(\"test\", label))\n",
        "        shutil.move(full_path, dir_name)\n",
        "\n",
        "      i += 1\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P05uaVocgcyy",
        "colab_type": "text"
      },
      "source": [
        "**Dataset and Dataloader Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDLOEt73gsa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5d369d42-54ab-4c18-c75e-8774fca390ac"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAIN_DIR = './train'\n",
        "VALID_DIR = './valid'\n",
        "TEST_DIR = './test'\n",
        "\n",
        "datagen_train = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "datagen_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "generator_train=datagen_train.flow_from_directory(TRAIN_DIR, target_size=(224,224), batch_size=32)\n",
        "\n",
        "generator_valid=datagen_test.flow_from_directory(VALID_DIR, target_size=(224, 224), batch_size=32)\n",
        "\n",
        "#generator_test=datagen_test.flow_from_directory(TEST_DIR)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13091 images belonging to 120 classes.\n",
            "Found 3327 images belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VF9HItToMGA",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9JjmJPgoNk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e81107b7-eb89-44ee-cfb1-cef6be1c9e80"
      },
      "source": [
        "STEP_SIZE = 200\n",
        "NUM_EPOCHS = 30\n",
        "VALID_STEP_SIZE = 80\n",
        "\n",
        "my_model = create_model()\n",
        "my_model = compile_model(my_model)\n",
        "best_model_path = 'saved_models/weights.bestaugmented.from_scratch.hdf5'\n",
        "chPointer = set_checkpointer(best_model_path)\n",
        "my_model = fit_gen(my_model, generator_train, STEP_SIZE, NUM_EPOCHS, generator_valid, VALID_STEP_SIZE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_19 (Batc (None, 224, 224, 3)       12        \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 222, 222, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 111, 111, 16)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 111, 111, 16)      64        \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 109, 109, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 54, 54, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 54, 54, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 52, 52, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 26, 26, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 10, 10, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 5, 5, 256)         1024      \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 425,444\n",
            "Trainable params: 424,446\n",
            "Non-trainable params: 998\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 109s 544ms/step - loss: 4.6186 - acc: 0.0333 - val_loss: 4.6029 - val_acc: 0.0492\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 103s 515ms/step - loss: 4.3843 - acc: 0.0517 - val_loss: 4.3086 - val_acc: 0.0528\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 105s 523ms/step - loss: 4.1741 - acc: 0.0789 - val_loss: 4.2156 - val_acc: 0.0633\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 105s 525ms/step - loss: 4.1114 - acc: 0.0805 - val_loss: 4.1604 - val_acc: 0.0770\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 104s 520ms/step - loss: 3.8927 - acc: 0.1103 - val_loss: 4.0811 - val_acc: 0.0840\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 104s 519ms/step - loss: 3.8116 - acc: 0.1249 - val_loss: 3.8749 - val_acc: 0.1200\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 104s 521ms/step - loss: 3.6322 - acc: 0.1467 - val_loss: 3.7535 - val_acc: 0.1297\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 104s 518ms/step - loss: 3.5862 - acc: 0.1611 - val_loss: 3.7169 - val_acc: 0.1223\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 104s 519ms/step - loss: 3.4164 - acc: 0.1873 - val_loss: 3.7973 - val_acc: 0.1242\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 105s 524ms/step - loss: 3.3462 - acc: 0.2037 - val_loss: 3.6870 - val_acc: 0.1297\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 104s 518ms/step - loss: 3.2278 - acc: 0.2275 - val_loss: 3.6750 - val_acc: 0.1282\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 104s 520ms/step - loss: 3.1178 - acc: 0.2392 - val_loss: 3.4596 - val_acc: 0.1825\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 106s 529ms/step - loss: 3.0240 - acc: 0.2650 - val_loss: 3.3988 - val_acc: 0.1841\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 105s 526ms/step - loss: 2.9674 - acc: 0.2739 - val_loss: 3.3158 - val_acc: 0.1945\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 105s 527ms/step - loss: 2.8266 - acc: 0.3023 - val_loss: 3.2495 - val_acc: 0.2102\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 104s 522ms/step - loss: 2.7686 - acc: 0.3102 - val_loss: 3.2366 - val_acc: 0.2200\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 103s 517ms/step - loss: 2.6746 - acc: 0.3354 - val_loss: 3.0932 - val_acc: 0.2403\n",
            "Epoch 18/30\n",
            "177/200 [=========================>....] - ETA: 10s - loss: 2.6617 - acc: 0.3409"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6999505a20be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'saved_models/weights.bestaugmented.from_scratch.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mchPointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_checkpointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVALID_STEP_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-2fd2e141f7ec>\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(model, _train_set, _steps_per_epoch, _epoch, _valid_set, _valid_steps)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_valid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     validation_steps = _valid_steps)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}