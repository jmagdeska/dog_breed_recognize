{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of [MLAI] Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ennTzcMfWbr1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfcSocyz7xLI",
        "colab_type": "code",
        "outputId": "7484eb50-e348-4e0a-cf4d-a38ed2180bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip3 install 'keras'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jz3SXYtGkSl",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyWOQ7ceGlkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import h5py\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "\n",
        "from keras import layers\n",
        "import keras.backend as K\n",
        "from keras import optimizers\n",
        "from keras import applications\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.utils import layer_utils\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "\n",
        "from keras.applications import xception\n",
        "from keras.applications import InceptionResNetV2\n",
        "from keras.applications import vgg16\n",
        "from keras.applications import resnet\n",
        "\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from matplotlib.pyplot import imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "np.random.seed(1000)\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bky2gGCc296",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree('test') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on6-T32ai4Te",
        "colab_type": "text"
      },
      "source": [
        "**Utility Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbXa_Qc5i8lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization(input_shape=(224, 224, 3)))\n",
        "  model.add(Conv2D(filters=16, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=32, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(filters=256, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(GlobalAveragePooling2D())\n",
        "\n",
        "  model.add(Dense(120, activation='softmax'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def compile_model(model, _opt='adam', _loss='categorical_crossentropy', _metrics=['accuracy']):\n",
        "  model.compile(_opt, _loss, _metrics)\n",
        "  return model\n",
        "\n",
        "def set_checkpointer(_filePath):\n",
        "  checkpointer = ModelCheckpoint(filepath=_filePath, verbose=1, \n",
        "                                 save_best_only=True)\n",
        "  return checkpointer\n",
        "\n",
        "def train(model, num_epochs, batch_size, step_size, train_data, train_target, valid_data, valid_target, checkpointer):\n",
        "  model.fit_generator(datagen.flow(train_data, train_target, batch_size=batch_size),\n",
        "                    validation_data=(valid_data, valid_target), \n",
        "                    steps_per_epoch=train_data.shape[0] // batch_size,\n",
        "                    epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "def fit_gen(model, _train_set, _steps_per_epoch, _epoch, _valid_set, _valid_steps=800):\n",
        "  model.fit_generator(\n",
        "    _train_set,\n",
        "    steps_per_epoch = _steps_per_epoch,\n",
        "    epochs = _epoch,\n",
        "    validation_data = _valid_set,\n",
        "    validation_steps = _valid_steps)\n",
        "  \n",
        "  return model\n",
        "\n",
        "# def load_best_model(model, _filePath):\n",
        "#   model.load_weights(_filePath)\n",
        "\n",
        "def test(model, test_data, test_target):\n",
        "  dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_data]\n",
        "\n",
        "  test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_target, axis=1))/len(dog_breed_predictions)\n",
        "  print('Test accuracy: %.4f%%' % test_accuracy)\n",
        "\n",
        "def save_dict_to_hdf5(dic, filename):\n",
        "  \"\"\"\n",
        "  ....\n",
        "  \"\"\"\n",
        "  with h5py.File(filename, 'w') as h5file:\n",
        "      recursively_save_dict_contents_to_group(h5file, '/', dic)\n",
        "\n",
        "def recursively_save_dict_contents_to_group(h5file, path, dic):\n",
        "    \"\"\"\n",
        "    ....\n",
        "    \"\"\"\n",
        "    for key, item in dic.items():\n",
        "        if isinstance(item, (np.ndarray, np.int64, np.float64, str, bytes)):\n",
        "            h5file[path + key] = item\n",
        "        elif isinstance(item, dict):\n",
        "            recursively_save_dict_contents_to_group(h5file, path + key + '/', item)\n",
        "        else:\n",
        "            raise ValueError('Cannot save %s type'%type(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHiId7xUeJpT",
        "colab_type": "text"
      },
      "source": [
        "**Dataset preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmQ5xfseM8-",
        "colab_type": "code",
        "outputId": "2da906a0-ea8c-444e-f579-93c14fcd1107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./mlai/Images'):\n",
        "  !git clone https://github.com/jmagdeska/mlai.git\n",
        "\n",
        "DATA_DIR = 'mlai/Images'\n",
        "\n",
        "if not os.path.isdir('train'):\n",
        "  os.mkdir('train')\n",
        "if not os.path.isdir('valid'):\n",
        "  os.mkdir('valid')\n",
        "if not os.path.isdir('test'):\n",
        "  os.mkdir('test')\n",
        "\n",
        "for path, dirs, files in os.walk(DATA_DIR):\n",
        "  dirs.sort(key = lambda x: x.lower())\n",
        "  num_samples = len(files)\n",
        "  i = 0\n",
        "  \n",
        "  l = (int)(0.8*num_samples)\n",
        "  if l != 0:\n",
        "    train_len = int(0.8*l)\n",
        "    valid_len = l - train_len\n",
        "    test_len = num_samples - l\n",
        "\n",
        "    label = path.split(\"/\")[2]\n",
        "    shuffle(files)\n",
        "\n",
        "    for filename in files: \n",
        "      full_path = os.path.join(path, filename)       \n",
        "      if i < train_len:   \n",
        "        split = 'train'     \n",
        "      elif i < (train_len + valid_len):\n",
        "        split = 'valid'\n",
        "      else:\n",
        "        split = 'test'\n",
        "      \n",
        "      dir_name = os.path.join(split, label)\n",
        "      if not os.path.isdir(dir_name):\n",
        "        os.mkdir(os.path.join(split, label))\n",
        "      shutil.move(full_path, dir_name)\n",
        "\n",
        "      i += 1  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mlai'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 41146 (delta 11), reused 3 (delta 0), pack-reused 41112\u001b[K\n",
            "Receiving objects: 100% (41146/41146), 1.38 GiB | 42.53 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "Checking out files: 100% (20581/20581), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P05uaVocgcyy",
        "colab_type": "text"
      },
      "source": [
        "**Dataset and Dataloader Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDLOEt73gsa-",
        "colab_type": "code",
        "outputId": "b91d54d3-4022-4d80-a3b6-0a8487e3417a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAIN_DIR = './train'\n",
        "VALID_DIR = './valid'\n",
        "TEST_DIR = './test'\n",
        "\n",
        "datagen_train = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "datagen_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "generator_train = datagen_train.flow_from_directory(TRAIN_DIR, target_size=(224,224), batch_size=32)\n",
        "\n",
        "generator_valid = datagen_test.flow_from_directory(VALID_DIR, target_size=(224, 224), batch_size=32)\n",
        "\n",
        "#generator_test=datagen_test.flow_from_directory(TEST_DIR)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13091 images belonging to 120 classes.\n",
            "Found 3327 images belonging to 120 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VF9HItToMGA",
        "colab_type": "text"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9JjmJPgoNk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEP_SIZE = 200\n",
        "NUM_EPOCHS = 30\n",
        "NUM_CLASSES = 120\n",
        "VALID_STEP_SIZE = 80\n",
        "\n",
        "######## Custom model #########\n",
        "# my_model = create_model()\n",
        "# my_model = compile_model(my_model)\n",
        "# best_model_path = 'saved_models/weights.bestaugmented.from_scratch.hdf5'\n",
        "# chPointer = set_checkpointer(best_model_path)\n",
        "# my_model = fit_gen(my_model, generator_train, STEP_SIZE, NUM_EPOCHS, generator_valid, VALID_STEP_SIZE)\n",
        "\n",
        "######## pretrained VGG16 model ########\n",
        "vgg_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# Freeze the layers except the last 4 layers\n",
        "for layer in vgg_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "my_model = Sequential()\n",
        "# Add the vgg convolutional base model\n",
        "my_model.add(vgg_model)\n",
        " \n",
        "# Add new layers\n",
        "my_model.add(Flatten())\n",
        "my_model.add(Dense(1024, activation='relu'))\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        " \n",
        "my_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "my_model = fit_gen(my_model, generator_train, STEP_SIZE, NUM_EPOCHS, generator_valid, VALID_STEP_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B11ux4x9NSh8",
        "colab_type": "text"
      },
      "source": [
        "**Training with Resnet101 with Inception v4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfpOLPuCNZET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a66d436-cc17-4ad9-d3ad-0c52f50e69aa"
      },
      "source": [
        "STEP_SIZE = 200\n",
        "NUM_EPOCHS = 30\n",
        "NUM_CLASSES = 120\n",
        "VALID_STEP_SIZE = 80\n",
        "\n",
        "######## pretrained VGG16 model ########\n",
        "model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        " \n",
        "my_model = Sequential()\n",
        "# Add the vgg convolutional base model\n",
        "my_model.add(model)\n",
        "\n",
        "# model.summary() \n",
        "# Add new layers\n",
        "my_model.add(Flatten())\n",
        "my_model.add(Dense(1024, activation='relu'))\n",
        "my_model.add(Dropout(0.5))\n",
        "my_model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
        " \n",
        "# my_model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "#               metrics=['acc'])\n",
        "# my_model = fit_gen(my_model, generator_train, STEP_SIZE, NUM_EPOCHS, generator_valid, VALID_STEP_SIZE)\n",
        "\n",
        "my_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-3),\n",
        "              metrics=['acc'])\n",
        "my_model = fit_gen(my_model, generator_train, STEP_SIZE, NUM_EPOCHS, generator_valid, VALID_STEP_SIZE)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 7s 0us/step\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 243s 1s/step - loss: 4.3244 - acc: 0.1253 - val_loss: 2.7173 - val_acc: 0.5445\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 160s 798ms/step - loss: 2.6367 - acc: 0.4314 - val_loss: 1.3814 - val_acc: 0.6987\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 157s 787ms/step - loss: 1.7516 - acc: 0.5861 - val_loss: 1.0031 - val_acc: 0.7565\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 153s 766ms/step - loss: 1.4217 - acc: 0.6536 - val_loss: 0.8617 - val_acc: 0.7788\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 154s 770ms/step - loss: 1.2139 - acc: 0.6866 - val_loss: 0.7837 - val_acc: 0.7910\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 152s 759ms/step - loss: 1.0297 - acc: 0.7295 - val_loss: 0.7803 - val_acc: 0.7909\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 154s 769ms/step - loss: 0.9566 - acc: 0.7495 - val_loss: 0.7131 - val_acc: 0.8077\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 150s 752ms/step - loss: 0.8915 - acc: 0.7562 - val_loss: 0.6750 - val_acc: 0.8144\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 153s 766ms/step - loss: 0.8195 - acc: 0.7722 - val_loss: 0.6621 - val_acc: 0.8207\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 151s 753ms/step - loss: 0.7981 - acc: 0.7779 - val_loss: 0.6814 - val_acc: 0.8085\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 153s 766ms/step - loss: 0.7547 - acc: 0.7864 - val_loss: 0.6321 - val_acc: 0.8222\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 150s 751ms/step - loss: 0.7491 - acc: 0.7941 - val_loss: 0.6118 - val_acc: 0.8261\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 152s 762ms/step - loss: 0.6905 - acc: 0.8034 - val_loss: 0.6548 - val_acc: 0.8281\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 151s 753ms/step - loss: 0.6639 - acc: 0.8155 - val_loss: 0.6396 - val_acc: 0.8285\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 152s 762ms/step - loss: 0.6126 - acc: 0.8245 - val_loss: 0.6079 - val_acc: 0.8300\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 150s 748ms/step - loss: 0.6411 - acc: 0.8194 - val_loss: 0.6247 - val_acc: 0.8331\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 152s 759ms/step - loss: 0.5725 - acc: 0.8402 - val_loss: 0.6153 - val_acc: 0.8245\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 150s 752ms/step - loss: 0.5785 - acc: 0.8317 - val_loss: 0.6341 - val_acc: 0.8297\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - 153s 763ms/step - loss: 0.5335 - acc: 0.8452 - val_loss: 0.6199 - val_acc: 0.8265\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 149s 746ms/step - loss: 0.5294 - acc: 0.8510 - val_loss: 0.6192 - val_acc: 0.8347\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 151s 757ms/step - loss: 0.4908 - acc: 0.8522 - val_loss: 0.6146 - val_acc: 0.8288\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - 149s 745ms/step - loss: 0.4971 - acc: 0.8575 - val_loss: 0.6152 - val_acc: 0.8348\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 151s 757ms/step - loss: 0.4724 - acc: 0.8617 - val_loss: 0.6096 - val_acc: 0.8355\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 149s 746ms/step - loss: 0.4747 - acc: 0.8603 - val_loss: 0.6300 - val_acc: 0.8312\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - 151s 755ms/step - loss: 0.4106 - acc: 0.8781 - val_loss: 0.5930 - val_acc: 0.8390\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 150s 752ms/step - loss: 0.4694 - acc: 0.8631 - val_loss: 0.6107 - val_acc: 0.8374\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 151s 753ms/step - loss: 0.3964 - acc: 0.8798 - val_loss: 0.5993 - val_acc: 0.8340\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 149s 747ms/step - loss: 0.4063 - acc: 0.8801 - val_loss: 0.6384 - val_acc: 0.8394\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 151s 754ms/step - loss: 0.3750 - acc: 0.8884 - val_loss: 0.6484 - val_acc: 0.8359\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 150s 749ms/step - loss: 0.3771 - acc: 0.8857 - val_loss: 0.5596 - val_acc: 0.8484\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}